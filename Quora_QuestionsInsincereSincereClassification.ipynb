{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01f361ddc47e0b386595316fe3d7f4dabbd260db",
    "id": "2mEeooLAcN3T"
   },
   "source": [
    "**Notebook Objective:**\n",
    "\n",
    "Objective of the notebook is to look at the different pretrained embeddings provided in the dataset and to see how they are useful in the model building process. \n",
    "\n",
    "First let us import the necessary modules and read the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z35l5ysZdD9Z"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4DOLuYqDdyrP"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "Bvw9DLdXcN3d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,  Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,GlobalMaxPooling1D,GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.python.keras.layers import CuDNNGRU,CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UrrZOzcolJWX"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SpatialDropout1D,Attention,concatenate,BatchNormalization,Reshape,Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "iXjoSv3PcN4x"
   },
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lSQgxjHDlFdD"
   },
   "outputs": [],
   "source": [
    "#Different Models - Model 1 ,2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iAN0tHguiiGV"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess():  \n",
    "  train_df = pd.read_csv(\"/content/sample_data/train.csv\")\n",
    "  print(\"Train shape : \",train_df.shape)\n",
    "  ## split to train and val\n",
    "  train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "  ## fill up the missing values\n",
    "  train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "  val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "  ## Tokenize the sentences\n",
    "  tokenizer = Tokenizer(num_words=max_features)\n",
    "  tokenizer.fit_on_texts(list(train_X))\n",
    "  train_X = tokenizer.texts_to_sequences(train_X)\n",
    "  val_X = tokenizer.texts_to_sequences(val_X)\n",
    "\n",
    "  ## Pad the sentences \n",
    "  train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "  val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "\n",
    "  ## Get the target values\n",
    "  train_y = train_df['target'].values\n",
    "  val_y = val_df['target'].values\n",
    "\n",
    "  return train_X,val_X,train_y,val_y,tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X5v6VSWbku7n"
   },
   "outputs": [],
   "source": [
    "def LSTM_GRU(embedding_matrix,spatialdropout=0.2, rnn_units=64, weight_decay=0.07):\n",
    "  K.clear_session()\n",
    "  x_input = Input(shape=(maxlen,))\n",
    "  \n",
    "  emb = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False, name='Embedding')(x_input)\n",
    "\n",
    "  x = SpatialDropout1D(spatialdropout, seed=1024)(emb)\n",
    "\n",
    "  rnn1 = Bidirectional(CuDNNLSTM(rnn_units, return_sequences=True, kernel_initializer=initializers.glorot_uniform(seed=111100), recurrent_initializer=initializers.Orthogonal(gain=1.0, seed=123000)))(x)\n",
    "\n",
    "  rnn2 = Bidirectional(CuDNNGRU(rnn_units, return_sequences=True, kernel_initializer=initializers.glorot_uniform(seed=111100), recurrent_initializer=initializers.Orthogonal(gain=1.0, seed=123000)))(rnn1)\n",
    "\n",
    "  x = concatenate([rnn1, rnn2])\n",
    "  x = GlobalMaxPooling1D()(x)\n",
    "  x_output = Dense(1, activation='sigmoid', kernel_initializer=initializers.glorot_uniform(seed=111100))(x)\n",
    "\n",
    "  model = Model(inputs=x_input, outputs=x_output)\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad1e9fdf97f3291a7d1797b25f0c7a0c5d1f1edd",
    "id": "J5mPqc7pcN5g"
   },
   "source": [
    "Next steps are as follows:\n",
    " * Split the training dataset into train and val sample. Cross validation is a time consuming process and so let us do simple train val split.\n",
    " * Fill up the missing values in the text column with '_na_'\n",
    " * Tokenize the text column and convert them to vector sequences\n",
    " * Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1ukKaH-jGpU",
    "outputId": "df04752c-d88f-4167-ffc6-5a38ff1ce867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-23 18:17:29--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
      "--2020-11-23 18:17:30--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2176768927 (2.0G) [application/zip]\n",
      "Saving to: ‘glove.840B.300d.zip’\n",
      "\n",
      "glove.840B.300d.zip 100%[===================>]   2.03G  1.99MB/s    in 16m 55s \n",
      "\n",
      "2020-11-23 18:34:25 (2.04 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://nlp.stanford.edu/data/glove.840B.300d.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-AmdoDNjIlM",
    "outputId": "9a791ada-b3fd-49c7-e54c-3ebb879baac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.840B.300d.zip\n",
      "  inflating: glove.840B.300d.txt     \n"
     ]
    }
   ],
   "source": [
    "!unzip 'glove.840B.300d.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "py_O0cigjJsB"
   },
   "outputs": [],
   "source": [
    "!rm 'glove.840B.300d.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ba5a1b8109dee2c9fbc628d5da4a7c3447d42fb8",
    "id": "Dx-5pP5XcN5l"
   },
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "  EMBEDDING_FILE = 'glove.840B.300d.txt'\n",
    "  def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "  all_embs = np.stack(embeddings_index.values())\n",
    "  emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "  embed_size = all_embs.shape[1]\n",
    "\n",
    "  #word_index = tokenizer.word_index\n",
    "  nb_words = min(max_features, len(word_index))\n",
    "  embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "  for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c0010e518288bc7f588776c58610949140a139a",
    "id": "1Noxns6ucOAC"
   },
   "source": [
    "We have four different types of embeddings.\n",
    " * GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
    " * glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
    " * paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
    " * wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
    " \n",
    "\n",
    "**Glove Embeddings:**\n",
    "\n",
    "In this section, let us use the Glove embeddings and rebuild the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z0dqGwek38L",
    "outputId": "71a8ade6-833e-4d37-a7ef-03122d6a84fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1317095, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_X,val_X,train_y,val_y,word_index = load_and_preprocess()\n",
    "emb_matrix1= load_glove(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a560ab0dbab9cf6fdbdae6721ec030e300f19d78",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JU09BMMBcOA0",
    "outputId": "7233a362-10d3-4163-8c58-c7c857db3787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2316/2316 [==============================] - 168s 72ms/step - loss: 0.1185 - accuracy: 0.9539 - val_loss: 0.1067 - val_accuracy: 0.9570\n",
      "Epoch 2/2\n",
      "2316/2316 [==============================] - 163s 70ms/step - loss: 0.1049 - accuracy: 0.9584 - val_loss: 0.1013 - val_accuracy: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f673e1080>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_GRU(emb_matrix1)\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "ff43855164472de035a5a1d80b3db4838684701a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNZTyWExcOBg",
    "outputId": "b27cddb2-d35f-4fd8-db9c-c23fba013e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 11s 87ms/step\n",
      "F1 score at threshold 0.1 is 0.5825047300833299\n",
      "F1 score at threshold 0.11 is 0.5925589461948219\n",
      "F1 score at threshold 0.12 is 0.6020723197293296\n",
      "F1 score at threshold 0.13 is 0.6093446654299151\n",
      "F1 score at threshold 0.14 is 0.6174184197812815\n",
      "F1 score at threshold 0.15 is 0.6237415544319657\n",
      "F1 score at threshold 0.16 is 0.6283012864221101\n",
      "F1 score at threshold 0.17 is 0.633581090439038\n",
      "F1 score at threshold 0.18 is 0.6382918817456593\n",
      "F1 score at threshold 0.19 is 0.6416424522459867\n",
      "F1 score at threshold 0.2 is 0.6449712713051036\n",
      "F1 score at threshold 0.21 is 0.6477895148669797\n",
      "F1 score at threshold 0.22 is 0.6503043198574892\n",
      "F1 score at threshold 0.23 is 0.6519298245614035\n",
      "F1 score at threshold 0.24 is 0.6538344337227019\n",
      "F1 score at threshold 0.25 is 0.6557090759669217\n",
      "F1 score at threshold 0.26 is 0.6586328693122793\n",
      "F1 score at threshold 0.27 is 0.6602553996531609\n",
      "F1 score at threshold 0.28 is 0.6617772108843537\n",
      "F1 score at threshold 0.29 is 0.6627632144391921\n",
      "F1 score at threshold 0.3 is 0.6647081225178172\n",
      "F1 score at threshold 0.31 is 0.6661536770363856\n",
      "F1 score at threshold 0.32 is 0.667480577136515\n",
      "F1 score at threshold 0.33 is 0.6693191370131689\n",
      "F1 score at threshold 0.34 is 0.6694584347235584\n",
      "F1 score at threshold 0.35 is 0.6697488584474887\n",
      "F1 score at threshold 0.36 is 0.6706621333487004\n",
      "F1 score at threshold 0.37 is 0.6703481950822531\n",
      "F1 score at threshold 0.38 is 0.670425182053089\n",
      "F1 score at threshold 0.39 is 0.6692717584369449\n",
      "F1 score at threshold 0.4 is 0.6683786204837264\n",
      "F1 score at threshold 0.41 is 0.6680740696061281\n",
      "F1 score at threshold 0.42 is 0.6664232243929158\n",
      "F1 score at threshold 0.43 is 0.6649086225929105\n",
      "F1 score at threshold 0.44 is 0.6632438451070147\n",
      "F1 score at threshold 0.45 is 0.6606295278541093\n",
      "F1 score at threshold 0.46 is 0.6598210910923522\n",
      "F1 score at threshold 0.47 is 0.6579700922685332\n",
      "F1 score at threshold 0.48 is 0.6549218800231467\n",
      "F1 score at threshold 0.49 is 0.6513951979234264\n",
      "F1 score at threshold 0.5 is 0.6488434571784286\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2a33c252f31fddcc65896053184226128562776",
    "id": "7pzZnEMIcOB4"
   },
   "source": [
    "Results seem to be better than the model without pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRBs1_Nul_Kz",
    "outputId": "e6e316b7-8f2a-458a-a705-d94a2bfca8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-23 18:47:50--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 681808098 (650M) [application/zip]\n",
      "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
      "\n",
      "wiki-news-300d-1M.v 100%[===================>] 650.22M  8.38MB/s    in 81s     \n",
      "\n",
      "2020-11-23 18:49:13 (8.03 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxL2IMUdmMkH",
    "outputId": "e74f0f82-0c65-4187-ae67-97c87cc3ed1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  wiki-news-300d-1M.vec.zip\n",
      "  inflating: wiki-news-300d-1M.vec   \n"
     ]
    }
   ],
   "source": [
    "!unzip 'wiki-news-300d-1M.vec.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JRoCbwsJmUIi"
   },
   "outputs": [],
   "source": [
    "!rm 'wiki-news-300d-1M.vec.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc6bab22dd12a09378f4b8b159cb7a5d88a3e7c0",
    "id": "bTUOdpqBcODF"
   },
   "source": [
    "**Wiki News FastText Embeddings:**\n",
    "\n",
    "Now let us use the FastText embeddings trained on Wiki News corpus in place of Glove embeddings and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6f3d0fd28dd2b04eaccb732b96b872e5a223d962",
    "id": "nqJuIQfUcODI"
   },
   "outputs": [],
   "source": [
    "def load_fasttext(word_index):\n",
    "  EMBEDDING_FILE = 'wiki-news-300d-1M.vec'\n",
    "  def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "  all_embs = np.stack(embeddings_index.values())\n",
    "  emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "  embed_size = all_embs.shape[1]\n",
    "\n",
    "  #word_index = tokenizer.word_index\n",
    "  nb_words = min(max_features, len(word_index))\n",
    "  embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "  for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXCeav0Zk9L3",
    "outputId": "ddd226a3-aa68-4240-9014-9d13b0946e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1317095, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_X,val_X,train_y,val_y,word_index = load_and_preprocess()\n",
    "emb_matrix2 = load_fasttext(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "47238831a4701c8a67dc7ecb130ac1402baf7bb2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3hhTJtXcODl",
    "outputId": "778d7668-341f-4d15-edc5-fe3ae2c77099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2316/2316 [==============================] - 161s 69ms/step - loss: 0.1266 - accuracy: 0.9515 - val_loss: 0.1111 - val_accuracy: 0.9564\n",
      "Epoch 2/2\n",
      "2316/2316 [==============================] - 160s 69ms/step - loss: 0.1105 - accuracy: 0.9567 - val_loss: 0.1051 - val_accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e4d2a2278>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_GRU(emb_matrix2)\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b7ab4100f723ad535528865b1edc7896bce80223",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2FuqwgRcOEA",
    "outputId": "0a7554a4-f137-4f2c-e871-255dcf87daef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 7s 56ms/step\n",
      "F1 score at threshold 0.1 is 0.5857629371210235\n",
      "F1 score at threshold 0.11 is 0.5957192292903831\n",
      "F1 score at threshold 0.12 is 0.6051592524348514\n",
      "F1 score at threshold 0.13 is 0.6134649910233393\n",
      "F1 score at threshold 0.14 is 0.6199816681943172\n",
      "F1 score at threshold 0.15 is 0.624959087296021\n",
      "F1 score at threshold 0.16 is 0.6309915581628273\n",
      "F1 score at threshold 0.17 is 0.6348189144577143\n",
      "F1 score at threshold 0.18 is 0.638430057689463\n",
      "F1 score at threshold 0.19 is 0.6424552943540285\n",
      "F1 score at threshold 0.2 is 0.6452730236348818\n",
      "F1 score at threshold 0.21 is 0.6478829550741871\n",
      "F1 score at threshold 0.22 is 0.6506719865602688\n",
      "F1 score at threshold 0.23 is 0.6516506922257721\n",
      "F1 score at threshold 0.24 is 0.6533340520726646\n",
      "F1 score at threshold 0.25 is 0.655598033861278\n",
      "F1 score at threshold 0.26 is 0.6551705079312441\n",
      "F1 score at threshold 0.27 is 0.6562464985994397\n",
      "F1 score at threshold 0.28 is 0.6566859476012249\n",
      "F1 score at threshold 0.29 is 0.6571428571428571\n",
      "F1 score at threshold 0.3 is 0.6554826725489058\n",
      "F1 score at threshold 0.31 is 0.6545967552316012\n",
      "F1 score at threshold 0.32 is 0.6535325278257248\n",
      "F1 score at threshold 0.33 is 0.6525479814692258\n",
      "F1 score at threshold 0.34 is 0.6536799172094722\n",
      "F1 score at threshold 0.35 is 0.6531415221935325\n",
      "F1 score at threshold 0.36 is 0.6520469652730323\n",
      "F1 score at threshold 0.37 is 0.6513588324106694\n",
      "F1 score at threshold 0.38 is 0.649598777225831\n",
      "F1 score at threshold 0.39 is 0.6479145211122554\n",
      "F1 score at threshold 0.4 is 0.6459797033567525\n",
      "F1 score at threshold 0.41 is 0.643101182654402\n",
      "F1 score at threshold 0.42 is 0.6395271616416524\n",
      "F1 score at threshold 0.43 is 0.6350164286193255\n",
      "F1 score at threshold 0.44 is 0.6311364252780037\n",
      "F1 score at threshold 0.45 is 0.6267470539873938\n",
      "F1 score at threshold 0.46 is 0.6246715530355414\n",
      "F1 score at threshold 0.47 is 0.6206269241533725\n",
      "F1 score at threshold 0.48 is 0.6161345012715457\n",
      "F1 score at threshold 0.49 is 0.6088012573224747\n",
      "F1 score at threshold 0.5 is 0.6021256597498372\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1312b7a4c3b67ca4ebd26fb083dbac3b6635dc2",
    "id": "KYloa4DMcOIQ"
   },
   "source": [
    "\n",
    " * The performance of the different pretrained embeddings are almost similar.\n",
    " \n",
    "**Final Blend:**\n",
    "\n",
    "Though the results of the models with different pre-trained embeddings are similar, there is a good chance that they might capture different type of information from the data. So let us do a blend of these three models by averaging their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "449bc59fdc9a719aa0759ac51a4481df113604ca",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HX-1pbblcOIT",
    "outputId": "90f6bcd0-79c9-45f7-9e95-6c8ef0afea7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5857536913840662\n",
      "F1 score at threshold 0.11 is 0.5966211717709721\n",
      "F1 score at threshold 0.12 is 0.6064323748668797\n",
      "F1 score at threshold 0.13 is 0.6146277753591641\n",
      "F1 score at threshold 0.14 is 0.6209527188858335\n",
      "F1 score at threshold 0.15 is 0.6283777677361049\n",
      "F1 score at threshold 0.16 is 0.6326774549466715\n",
      "F1 score at threshold 0.17 is 0.6375023368853991\n",
      "F1 score at threshold 0.18 is 0.641462835431014\n",
      "F1 score at threshold 0.19 is 0.6469509841759937\n",
      "F1 score at threshold 0.2 is 0.6489871807417557\n",
      "F1 score at threshold 0.21 is 0.65228602598433\n",
      "F1 score at threshold 0.22 is 0.6554325955734406\n",
      "F1 score at threshold 0.23 is 0.6576208936951642\n",
      "F1 score at threshold 0.24 is 0.6600475747233427\n",
      "F1 score at threshold 0.25 is 0.6627529091099696\n",
      "F1 score at threshold 0.26 is 0.663236074270557\n",
      "F1 score at threshold 0.27 is 0.6644144144144144\n",
      "F1 score at threshold 0.28 is 0.664930272939389\n",
      "F1 score at threshold 0.29 is 0.6669229079727651\n",
      "F1 score at threshold 0.3 is 0.668551471811076\n",
      "F1 score at threshold 0.31 is 0.6707043517272319\n",
      "F1 score at threshold 0.32 is 0.6713897075493085\n",
      "F1 score at threshold 0.33 is 0.67177843900206\n",
      "F1 score at threshold 0.34 is 0.6716763005780347\n",
      "F1 score at threshold 0.35 is 0.6707188778492109\n",
      "F1 score at threshold 0.36 is 0.6700489646628517\n",
      "F1 score at threshold 0.37 is 0.669925484351714\n",
      "F1 score at threshold 0.38 is 0.6685927530997954\n",
      "F1 score at threshold 0.39 is 0.6675567423230975\n",
      "F1 score at threshold 0.4 is 0.6664213431462742\n",
      "F1 score at threshold 0.41 is 0.6650978449343572\n",
      "F1 score at threshold 0.42 is 0.6636238589471051\n",
      "F1 score at threshold 0.43 is 0.6630050505050505\n",
      "F1 score at threshold 0.44 is 0.6598201186451489\n",
      "F1 score at threshold 0.45 is 0.657820149446019\n",
      "F1 score at threshold 0.46 is 0.6549973971889641\n",
      "F1 score at threshold 0.47 is 0.6508447833804484\n",
      "F1 score at threshold 0.48 is 0.6451141795007965\n",
      "F1 score at threshold 0.49 is 0.6412131785546534\n",
      "F1 score at threshold 0.5 is 0.6377066955814583\n"
     ]
    }
   ],
   "source": [
    "pred_val_y = 0.67*pred_glove_val_y + 0.33*pred_fasttext_val_y\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fdbeffc0f84643d2832eec49234bd9d6c6e216b",
    "id": "HDLA4jYmcOIp"
   },
   "source": [
    "The result seems to better than individual pre-trained models and so we let us \n",
    "create a submission file using this model blend.Let us try the 2 embeddings with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qE9BbzEqfFFS"
   },
   "outputs": [],
   "source": [
    "def BiLSTM_CNN(embedding_matrix,spatialdropout=0.2, rnn_units=128, filters=[100, 80, 30, 12], weight_decay=0.10):\n",
    "  K.clear_session()\n",
    "  x_input = Input(shape=(maxlen,))\n",
    "  \n",
    "  emb = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False, name='Embedding')(x_input)\n",
    "\n",
    "  x = SpatialDropout1D(rate=spatialdropout, seed=10000)(emb)\n",
    "\n",
    "  rnn = Bidirectional(CuDNNLSTM(rnn_units, return_sequences=True, kernel_initializer=initializers.glorot_uniform(seed=123000), recurrent_initializer=initializers.Orthogonal(gain=1.0, seed=123000)))(x)\n",
    "  \n",
    "  x1 = Conv1D(filters=filters[0], activation='relu', kernel_size=1, padding='same', kernel_initializer=initializers.glorot_uniform(seed=110000))(rnn)\n",
    "  x2 = Conv1D(filters=filters[1], activation='relu', kernel_size=1, padding='same', kernel_initializer=initializers.glorot_uniform(seed=120000))(rnn)\n",
    "  x3 = Conv1D(filters=filters[2], activation='relu', kernel_size=1, padding='same', kernel_initializer=initializers.glorot_uniform(seed=130000))(rnn)\n",
    "  x4 = Conv1D(filters=filters[3], activation='relu', kernel_size=1, padding='same', kernel_initializer=initializers.glorot_uniform(seed=140000))(rnn)\n",
    "\n",
    "  x1 = GlobalMaxPooling1D()(x1)\n",
    "  x2 = GlobalMaxPooling1D()(x2)\n",
    "  x3 = GlobalMaxPooling1D()(x3)\n",
    "  x4 = GlobalMaxPooling1D()(x4)\n",
    "\n",
    "  c = concatenate([x1, x2, x3, x4])\n",
    "  x = Dense(200, activation='relu', kernel_initializer=initializers.glorot_uniform(seed=111000))(c)\n",
    "  x = Dropout(0.2, seed=10000)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x_output = Dense(1, activation='sigmoid', kernel_initializer=initializers.glorot_uniform(seed=110000))(x)\n",
    " \n",
    "  model = Model(inputs=x_input, outputs=x_output)\n",
    "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3Ru3CIQkM0g",
    "outputId": "5d3e4afe-c55a-46a0-88c8-8ff85e8bf4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1317095, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_X,val_X,train_y,val_y,word_index = load_and_preprocess()\n",
    "emb_matrix3= load_glove(word_index)\n",
    "model = BiLSTM_CNN(emb_matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrsovvKmkM4a",
    "outputId": "50958176-3523-4a45-fc60-b3debeb8d1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2316/2316 [==============================] - 217s 94ms/step - loss: 0.1293 - accuracy: 0.9498 - val_loss: 0.1111 - val_accuracy: 0.9554\n",
      "Epoch 2/2\n",
      "2316/2316 [==============================] - 214s 92ms/step - loss: 0.1057 - accuracy: 0.9581 - val_loss: 0.1018 - val_accuracy: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1b147e4f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OW6Y73xkNPY",
    "outputId": "8707ef76-2d6a-4664-ee77-791f81dd7920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 11s 83ms/step\n",
      "F1 score at threshold 0.1 is 0.562726890595743\n",
      "F1 score at threshold 0.11 is 0.5728383458646616\n",
      "F1 score at threshold 0.12 is 0.5814586502281643\n",
      "F1 score at threshold 0.13 is 0.5904403339335407\n",
      "F1 score at threshold 0.14 is 0.5984895898527142\n",
      "F1 score at threshold 0.15 is 0.6049534814563066\n",
      "F1 score at threshold 0.16 is 0.611545945945946\n",
      "F1 score at threshold 0.17 is 0.6182746029651138\n",
      "F1 score at threshold 0.18 is 0.624151482672383\n",
      "F1 score at threshold 0.19 is 0.629167611703334\n",
      "F1 score at threshold 0.2 is 0.6344155246941966\n",
      "F1 score at threshold 0.21 is 0.6390146036485793\n",
      "F1 score at threshold 0.22 is 0.6428132532967813\n",
      "F1 score at threshold 0.23 is 0.6471123020240204\n",
      "F1 score at threshold 0.24 is 0.6497142303593917\n",
      "F1 score at threshold 0.25 is 0.6524697704019189\n",
      "F1 score at threshold 0.26 is 0.6549093431090854\n",
      "F1 score at threshold 0.27 is 0.6571928946710033\n",
      "F1 score at threshold 0.28 is 0.6592082616179001\n",
      "F1 score at threshold 0.29 is 0.6621282694374776\n",
      "F1 score at threshold 0.3 is 0.6633504326649049\n",
      "F1 score at threshold 0.31 is 0.6656194365902189\n",
      "F1 score at threshold 0.32 is 0.6672663773944333\n",
      "F1 score at threshold 0.33 is 0.6688419363466168\n",
      "F1 score at threshold 0.34 is 0.6696886298634721\n",
      "F1 score at threshold 0.35 is 0.6707735921059805\n",
      "F1 score at threshold 0.36 is 0.6711120908189132\n",
      "F1 score at threshold 0.37 is 0.6715620827770361\n",
      "F1 score at threshold 0.38 is 0.6718688598214788\n",
      "F1 score at threshold 0.39 is 0.6726747151844924\n",
      "F1 score at threshold 0.4 is 0.6714326565627681\n",
      "F1 score at threshold 0.41 is 0.6713593353334872\n",
      "F1 score at threshold 0.42 is 0.6711737964797763\n",
      "F1 score at threshold 0.43 is 0.669766894278314\n",
      "F1 score at threshold 0.44 is 0.6688057040998218\n",
      "F1 score at threshold 0.45 is 0.6678672189207036\n",
      "F1 score at threshold 0.46 is 0.6671109226388804\n",
      "F1 score at threshold 0.47 is 0.6663814180929095\n",
      "F1 score at threshold 0.48 is 0.6635813896087869\n",
      "F1 score at threshold 0.49 is 0.6611786716557531\n",
      "F1 score at threshold 0.5 is 0.6587865451116002\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfzIQ8FUkNXH",
    "outputId": "0851fba7-d7f6-4d55-fd36-176dc7b45d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1317095, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_X,val_X,train_y,val_y,word_index = load_and_preprocess()\n",
    "emb_matrix4 = load_fasttext(word_index)\n",
    "model = BiLSTM_CNN(emb_matrix4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVY3KVJ-kNjR",
    "outputId": "a0607482-6bba-4741-be5a-1357dec22b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2316/2316 [==============================] - 214s 92ms/step - loss: 0.1316 - accuracy: 0.9496 - val_loss: 0.1236 - val_accuracy: 0.9532\n",
      "Epoch 2/2\n",
      "2316/2316 [==============================] - 212s 92ms/step - loss: 0.1094 - accuracy: 0.9573 - val_loss: 0.1088 - val_accuracy: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18fb30ea20>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIFY4Ig4kNzr",
    "outputId": "7bc537ad-cad1-4038-897d-95b04a60f6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/129 [..............................] - ETA: 5sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0305s vs `on_predict_batch_end` time: 0.0587s). Check your callbacks.\n",
      "129/129 [==============================] - 9s 67ms/step\n",
      "F1 score at threshold 0.1 is 0.6119603110753553\n",
      "F1 score at threshold 0.11 is 0.620252583237658\n",
      "F1 score at threshold 0.12 is 0.6271514122695336\n",
      "F1 score at threshold 0.13 is 0.6334636359249072\n",
      "F1 score at threshold 0.14 is 0.6378010935421901\n",
      "F1 score at threshold 0.15 is 0.6433792025807752\n",
      "F1 score at threshold 0.16 is 0.6482673394778847\n",
      "F1 score at threshold 0.17 is 0.6506137865911238\n",
      "F1 score at threshold 0.18 is 0.6525967086984399\n",
      "F1 score at threshold 0.19 is 0.6531788763800511\n",
      "F1 score at threshold 0.2 is 0.6536628615759725\n",
      "F1 score at threshold 0.21 is 0.6546336510801513\n",
      "F1 score at threshold 0.22 is 0.6551013397457918\n",
      "F1 score at threshold 0.23 is 0.6544186046511629\n",
      "F1 score at threshold 0.24 is 0.6533648170011805\n",
      "F1 score at threshold 0.25 is 0.6527286886718985\n",
      "F1 score at threshold 0.26 is 0.6524908869987849\n",
      "F1 score at threshold 0.27 is 0.6512716300264796\n",
      "F1 score at threshold 0.28 is 0.6483180428134557\n",
      "F1 score at threshold 0.29 is 0.6455240381578116\n",
      "F1 score at threshold 0.3 is 0.6435294870973939\n",
      "F1 score at threshold 0.31 is 0.6392126392126392\n",
      "F1 score at threshold 0.32 is 0.6356782272339867\n",
      "F1 score at threshold 0.33 is 0.633512366553942\n",
      "F1 score at threshold 0.34 is 0.6315718884120172\n",
      "F1 score at threshold 0.35 is 0.6284512583949529\n",
      "F1 score at threshold 0.36 is 0.6244170096021949\n",
      "F1 score at threshold 0.37 is 0.6207757962667407\n",
      "F1 score at threshold 0.38 is 0.6144544431946007\n",
      "F1 score at threshold 0.39 is 0.6084667378157239\n",
      "F1 score at threshold 0.4 is 0.6023454924814734\n",
      "F1 score at threshold 0.41 is 0.59327350988546\n",
      "F1 score at threshold 0.42 is 0.5868714465037289\n",
      "F1 score at threshold 0.43 is 0.578884402572155\n",
      "F1 score at threshold 0.44 is 0.5711905483186912\n",
      "F1 score at threshold 0.45 is 0.5639610638460949\n",
      "F1 score at threshold 0.46 is 0.5551761601738321\n",
      "F1 score at threshold 0.47 is 0.5472409998427921\n",
      "F1 score at threshold 0.48 is 0.5398568019093078\n",
      "F1 score at threshold 0.49 is 0.5286428917218009\n",
      "F1 score at threshold 0.5 is 0.5210221242550412\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3p-NRCDnVT4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "history_visible": true,
   "name": "Quora_QuestionsInsincereSincereClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
